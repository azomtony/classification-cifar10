{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e67804-450c-4df5-8f21-86e2d954f83c",
   "metadata": {},
   "source": [
    "#Imports and CIFAR-10 Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d0e3d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\ehayfo1\\appdata\\local\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\ehayfo1\\appdata\\local\\anaconda3\\lib\\site-packages (from keras) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\ehayfo1\\appdata\\local\\anaconda3\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\ehayfo1\\appdata\\local\\anaconda3\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\ehayfo1\\appdata\\local\\anaconda3\\lib\\site-packages (from keras) (0.0.9)\n",
      "Requirement already satisfied: h5py in c:\\users\\ehayfo1\\appdata\\local\\anaconda3\\lib\\site-packages (from keras) (3.13.0)\n",
      "Requirement already satisfied: optree in c:\\users\\ehayfo1\\appdata\\local\\anaconda3\\lib\\site-packages (from keras) (0.15.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\ehayfo1\\appdata\\local\\anaconda3\\lib\\site-packages (from keras) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\ehayfo1\\appdata\\local\\anaconda3\\lib\\site-packages (from keras) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\ehayfo1\\appdata\\local\\anaconda3\\lib\\site-packages (from optree->keras) (4.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ehayfo1\\appdata\\local\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ehayfo1\\appdata\\local\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ehayfo1\\appdata\\local\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37df85e9-3c87-4a10-ba9e-411f2043e3d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"C:\\Users\\ehayfo1\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cifar10\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, accuracy_score\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[0m\n\u001b[0;32m     86\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     92\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     93\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     94\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     95\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"C:\\Users\\ehayfo1\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Flatten label arrays to 1D\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "# Display dataset dimensions\n",
    "print(\"CIFAR-10 Dataset Loaded\")\n",
    "print(f\"Training images: {x_train.shape}\")\n",
    "print(f\"Test images:     {x_test.shape}\")\n",
    "print(f\"Training labels: {y_train.shape}\")\n",
    "print(f\"Test labels:     {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5830a9e-d2ab-482a-8036-a87cea130d93",
   "metadata": {},
   "source": [
    "#Baseline Logistic Regression (Raw RGB Pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c777b84-0526-4a1f-ad5a-15119c95e454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy (Raw RGB): 0.3471\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40      1000\n",
      "           1       0.42      0.38      0.40      1000\n",
      "           2       0.27      0.27      0.27      1000\n",
      "           3       0.23      0.21      0.22      1000\n",
      "           4       0.31      0.28      0.29      1000\n",
      "           5       0.28      0.27      0.28      1000\n",
      "           6       0.37      0.38      0.37      1000\n",
      "           7       0.40      0.40      0.40      1000\n",
      "           8       0.40      0.52      0.45      1000\n",
      "           9       0.38      0.36      0.37      1000\n",
      "\n",
      "    accuracy                           0.35     10000\n",
      "   macro avg       0.35      0.35      0.35     10000\n",
      "weighted avg       0.35      0.35      0.35     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Flatten image data to 1D vectors\n",
    "x_train_rgb = x_train.reshape((x_train.shape[0], -1))\n",
    "x_test_rgb = x_test.reshape((x_test.shape[0], -1))\n",
    "\n",
    "# Train logistic regression on a subset of training data\n",
    "model_rgb = LogisticRegression(\n",
    "    max_iter=300,\n",
    "    solver='saga',\n",
    "    multi_class='multinomial',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model_rgb.fit(x_train_rgb[:10000], y_train[:10000])\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rgb = model_rgb.predict(x_test_rgb)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy_rgb = accuracy_score(y_test, y_pred_rgb)\n",
    "print(f\"Baseline Accuracy (Raw RGB): {accuracy_rgb:.4f}\")\n",
    "print(classification_report(y_test, y_pred_rgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca2b4bc-849b-44ed-be99-f46729e361d2",
   "metadata": {},
   "source": [
    "#Hyperparameter Tuning on Raw RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b70599-0cf8-476a-883f-73e5c3fd260a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] END C=0.1, max_iter=300, multi_class=multinomial, solver=saga; total time= 3.3min\n",
      "[CV] END C=0.1, max_iter=300, multi_class=multinomial, solver=saga; total time= 3.3min\n",
      "[CV] END C=0.1, max_iter=300, multi_class=multinomial, solver=saga; total time= 3.2min\n",
      "[CV] END C=1, max_iter=300, multi_class=multinomial, solver=saga; total time=13.0min\n",
      "[CV] END C=1, max_iter=300, multi_class=multinomial, solver=saga; total time= 3.2min\n",
      "[CV] END C=1, max_iter=300, multi_class=multinomial, solver=saga; total time= 3.2min\n",
      "[CV] END C=10, max_iter=300, multi_class=multinomial, solver=saga; total time= 3.2min\n",
      "[CV] END C=10, max_iter=300, multi_class=multinomial, solver=saga; total time= 3.3min\n",
      "[CV] END C=10, max_iter=300, multi_class=multinomial, solver=saga; total time= 3.2min\n",
      "Tuned Accuracy (Raw RGB): 0.3467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40      1000\n",
      "           1       0.42      0.38      0.40      1000\n",
      "           2       0.27      0.27      0.27      1000\n",
      "           3       0.23      0.22      0.22      1000\n",
      "           4       0.30      0.28      0.29      1000\n",
      "           5       0.28      0.27      0.28      1000\n",
      "           6       0.37      0.38      0.37      1000\n",
      "           7       0.40      0.40      0.40      1000\n",
      "           8       0.40      0.52      0.45      1000\n",
      "           9       0.38      0.36      0.37      1000\n",
      "\n",
      "    accuracy                           0.35     10000\n",
      "   macro avg       0.34      0.35      0.34     10000\n",
      "weighted avg       0.34      0.35      0.34     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],                # Regularization strength\n",
    "    'solver': ['saga'],              # Optimized solver for multinomial LR\n",
    "    'multi_class': ['multinomial'],  # Multiclass mode\n",
    "    'max_iter': [300]                # Max training iterations\n",
    "}\n",
    "\n",
    "# Initialize grid search\n",
    "grid_rgb = GridSearchCV(\n",
    "    LogisticRegression(n_jobs=-1),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit using subset for speed (same as Phase 1)\n",
    "grid_rgb.fit(x_train_rgb[:10000], y_train[:10000])\n",
    "\n",
    "# Evaluate best model from grid\n",
    "best_rgb_model = grid_rgb.best_estimator_\n",
    "y_pred_rgb_tuned = best_rgb_model.predict(x_test_rgb)\n",
    "\n",
    "# Accuracy report\n",
    "tuned_rgb_accuracy = accuracy_score(y_test, y_pred_rgb_tuned)\n",
    "print(f\"Tuned Accuracy (Raw RGB): {tuned_rgb_accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred_rgb_tuned))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d052af4-ddd9-41b1-a041-441d2b37ae49",
   "metadata": {},
   "source": [
    "#Advanced Preprocessing Techniques for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54849c5d-39c9-42e1-bfe1-d9a388747c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.24.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\egyin\\anaconda3\\envs\\csc7333_ml_project\\lib\\site-packages (from scikit-image) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\egyin\\anaconda3\\envs\\csc7333_ml_project\\lib\\site-packages (from scikit-image) (1.13.1)\n",
      "Collecting networkx>=2.8 (from scikit-image)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\egyin\\anaconda3\\envs\\csc7333_ml_project\\lib\\site-packages (from scikit-image) (11.1.0)\n",
      "Collecting imageio>=2.33 (from scikit-image)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2024.8.30-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\egyin\\anaconda3\\envs\\csc7333_ml_project\\lib\\site-packages (from scikit-image) (24.2)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Downloading scikit_image-0.24.0-cp39-cp39-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 10.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.7/12.9 MB 10.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.8/12.9 MB 9.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.1/12.9 MB 10.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.2/12.9 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.9 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 10.0 MB/s eta 0:00:00\n",
      "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 9.8 MB/s eta 0:00:00\n",
      "Downloading tifffile-2024.8.30-py3-none-any.whl (227 kB)\n",
      "Installing collected packages: tifffile, networkx, lazy-loader, imageio, scikit-image\n",
      "Successfully installed imageio-2.37.0 lazy-loader-0.4 networkx-3.2.1 scikit-image-0.24.0 tifffile-2024.8.30\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "261fb88a-fc8e-47ea-8a51-6897a447c8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (HOG): 0.4961\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56      1000\n",
      "           1       0.57      0.59      0.58      1000\n",
      "           2       0.43      0.40      0.42      1000\n",
      "           3       0.38      0.30      0.34      1000\n",
      "           4       0.41      0.44      0.42      1000\n",
      "           5       0.42      0.38      0.40      1000\n",
      "           6       0.48      0.61      0.54      1000\n",
      "           7       0.55      0.54      0.55      1000\n",
      "           8       0.54      0.54      0.54      1000\n",
      "           9       0.59      0.60      0.59      1000\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.49      0.50      0.49     10000\n",
      "weighted avg       0.49      0.50      0.49     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#HOG + Logistic Regression\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "# Convert to grayscale\n",
    "x_train_gray = rgb2gray(x_train)\n",
    "x_test_gray = rgb2gray(x_test)\n",
    "\n",
    "# Extract HOG features\n",
    "def extract_hog_features(images):\n",
    "    features = []\n",
    "    for image in images:\n",
    "        hog_feat = hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), feature_vector=True)\n",
    "        features.append(hog_feat)\n",
    "    return np.array(features)\n",
    "\n",
    "# For runtime: use subset of training for now\n",
    "x_train_hog = extract_hog_features(x_train_gray[:10000])\n",
    "x_test_hog = extract_hog_features(x_test_gray)\n",
    "\n",
    "# Train logistic regression\n",
    "hog_lr = LogisticRegression(max_iter=300, solver='saga', multi_class='multinomial', n_jobs=-1)\n",
    "hog_lr.fit(x_train_hog, y_train[:10000])\n",
    "\n",
    "# Evaluate\n",
    "y_pred_hog = hog_lr.predict(x_test_hog)\n",
    "print(\"Accuracy (HOG):\", accuracy_score(y_test, y_pred_hog))\n",
    "print(classification_report(y_test, y_pred_hog))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484b921d-9c32-4997-8cc8-86ff66a163b6",
   "metadata": {},
   "source": [
    "# CLAHE + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c9dec2c-cee3-4cb2-95a1-8d5f0143bd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\egyin\\anaconda3\\envs\\csc7333_ml_project\\lib\\site-packages (from opencv-python-headless) (1.26.4)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl (39.4 MB)\n",
      "   ---------------------------------------- 0.0/39.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/39.4 MB 8.4 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.9/39.4 MB 8.0 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 5.2/39.4 MB 9.1 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 7.3/39.4 MB 9.4 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 9.4/39.4 MB 9.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 11.3/39.4 MB 9.3 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 13.1/39.4 MB 9.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 14.9/39.4 MB 9.2 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 16.3/39.4 MB 9.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 18.6/39.4 MB 9.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 20.4/39.4 MB 9.0 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 22.5/39.4 MB 9.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 24.9/39.4 MB 9.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 27.3/39.4 MB 9.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.6/39.4 MB 9.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.7/39.4 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.8/39.4 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 36.4/39.4 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/39.4 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.4/39.4 MB 9.6 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.11.0.86\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python-headless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b0f6c2-b457-41a8-ba8b-17b8d5c6390c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (CLAHE): 0.1916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.21      0.22      1000\n",
      "           1       0.23      0.22      0.22      1000\n",
      "           2       0.16      0.18      0.17      1000\n",
      "           3       0.15      0.13      0.14      1000\n",
      "           4       0.13      0.13      0.13      1000\n",
      "           5       0.17      0.15      0.16      1000\n",
      "           6       0.17      0.17      0.17      1000\n",
      "           7       0.20      0.22      0.21      1000\n",
      "           8       0.25      0.26      0.25      1000\n",
      "           9       0.24      0.25      0.25      1000\n",
      "\n",
      "    accuracy                           0.19     10000\n",
      "   macro avg       0.19      0.19      0.19     10000\n",
      "weighted avg       0.19      0.19      0.19     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# CLAHE enhancement\n",
    "def apply_clahe(images):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced = []\n",
    "    for img in images:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        eq = clahe.apply(gray)\n",
    "        enhanced.append(eq.flatten())  # Flatten to 1D for LR\n",
    "    return np.array(enhanced)\n",
    "\n",
    "# Apply CLAHE to training and test images\n",
    "x_train_clahe = apply_clahe(x_train[:10000])\n",
    "x_test_clahe = apply_clahe(x_test)\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "x_train_clahe_scaled = scaler.fit_transform(x_train_clahe)\n",
    "x_test_clahe_scaled = scaler.transform(x_test_clahe)\n",
    "\n",
    "# Train logistic regression\n",
    "clahe_lr = LogisticRegression(max_iter=300, solver='saga', multi_class='multinomial', n_jobs=-1)\n",
    "clahe_lr.fit(x_train_clahe_scaled, y_train[:10000])\n",
    "\n",
    "# Evaluate\n",
    "y_pred_clahe = clahe_lr.predict(x_test_clahe_scaled)\n",
    "print(\"Accuracy (CLAHE):\", accuracy_score(y_test, y_pred_clahe))\n",
    "print(classification_report(y_test, y_pred_clahe))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d0dfba-5ca6-47fe-8d3c-c46ca662aecc",
   "metadata": {},
   "source": [
    "#HSV Preprocessing + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8c5b912-02aa-492b-bcb3-fa899cf66d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (HSV): 0.2718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.36      0.34      1000\n",
      "           1       0.38      0.35      0.36      1000\n",
      "           2       0.18      0.19      0.18      1000\n",
      "           3       0.19      0.19      0.19      1000\n",
      "           4       0.20      0.21      0.21      1000\n",
      "           5       0.20      0.20      0.20      1000\n",
      "           6       0.29      0.29      0.29      1000\n",
      "           7       0.27      0.25      0.26      1000\n",
      "           8       0.34      0.38      0.36      1000\n",
      "           9       0.35      0.30      0.32      1000\n",
      "\n",
      "    accuracy                           0.27     10000\n",
      "   macro avg       0.27      0.27      0.27     10000\n",
      "weighted avg       0.27      0.27      0.27     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Convert RGB to HSV (OpenCV expects BGR, but CIFAR-10 is RGB, so conversion is fine)\n",
    "x_train_hsv = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2HSV) for img in x_train[:10000]])\n",
    "x_test_hsv = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2HSV) for img in x_test])\n",
    "\n",
    "# Flatten\n",
    "x_train_hsv_flat = x_train_hsv.reshape((x_train_hsv.shape[0], -1))\n",
    "x_test_hsv_flat = x_test_hsv.reshape((x_test_hsv.shape[0], -1))\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "x_train_hsv_scaled = scaler.fit_transform(x_train_hsv_flat)\n",
    "x_test_hsv_scaled = scaler.transform(x_test_hv_flat)\n",
    "\n",
    "# Logistic Regression\n",
    "hsv_lr = LogisticRegression(max_iter=300, solver='saga', multi_class='multinomial', n_jobs=-1)\n",
    "hsv_lr.fit(x_train_hsv_scaled, y_train[:10000])\n",
    "y_pred_hsv = hsv_lr.predict(x_test_hsv_scaled)\n",
    "\n",
    "# Evaluation\n",
    "hsv_acc = accuracy_score(y_test, y_pred_hsv)\n",
    "print(f\"Accuracy (HSV): {hsv_acc:.4f}\")\n",
    "print(classification_report(y_test, y_pred_hsv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1412dba6-ebd0-4dec-98a9-e6dd38d7be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA Preprocessing + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e12d4299-52b6-4d63-a57e-6c5a04eeede2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Accuracy: 0.3807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.46      0.45      1000\n",
      "           1       0.46      0.46      0.46      1000\n",
      "           2       0.28      0.28      0.28      1000\n",
      "           3       0.29      0.26      0.27      1000\n",
      "           4       0.32      0.25      0.28      1000\n",
      "           5       0.34      0.30      0.32      1000\n",
      "           6       0.39      0.47      0.43      1000\n",
      "           7       0.41      0.40      0.41      1000\n",
      "           8       0.44      0.51      0.47      1000\n",
      "           9       0.41      0.41      0.41      1000\n",
      "\n",
      "    accuracy                           0.38     10000\n",
      "   macro avg       0.38      0.38      0.38     10000\n",
      "weighted avg       0.38      0.38      0.38     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "# Subset for runtime efficiency\n",
    "x_train_subset = x_train[:10000]\n",
    "y_train_subset = y_train[:10000]\n",
    "\n",
    "# Flatten RGB images\n",
    "x_train_flat = x_train_subset.reshape((x_train_subset.shape[0], -1))\n",
    "x_test_flat = x_test.reshape((x_test.shape[0], -1))\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train_flat)\n",
    "x_test_scaled = scaler.transform(x_test_flat)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=150)  # You can tweak this value (e.g., 100â€“200)\n",
    "x_train_pca = pca.fit_transform(x_train_scaled)\n",
    "x_test_pca = pca.transform(x_test_scaled)\n",
    "\n",
    "# Logistic Regression\n",
    "pca_lr = LogisticRegression(max_iter=300, solver='saga', multi_class='multinomial', n_jobs=-1)\n",
    "pca_lr.fit(x_train_pca, y_train_subset)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_pca = pca_lr.predict(x_test_pca)\n",
    "print(f\"PCA Accuracy: {accuracy_score(y_test, y_pred_pca):.4f}\")\n",
    "print(classification_report(y_test, y_pred_pca))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b582bf5-a6fb-42b3-8147-b900a8fb6179",
   "metadata": {},
   "source": [
    "#Accuracy vs. Regularization Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c746cfe4-00f0-40e6-bded-b8a8d27fb82c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Prepare flattened RGB data (if not already done)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m x_train_rgb \u001b[38;5;241m=\u001b[39m x_train\u001b[38;5;241m.\u001b[39mreshape((x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      7\u001b[0m x_test_rgb \u001b[38;5;241m=\u001b[39m x_test\u001b[38;5;241m.\u001b[39mreshape((x_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Use a subset to speed up\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Prepare flattened RGB data (if not already done)\n",
    "x_train_rgb = x_train.reshape((x_train.shape[0], -1))\n",
    "x_test_rgb = x_test.reshape((x_test.shape[0], -1))\n",
    "\n",
    "# Use a subset to speed up\n",
    "x_train_sub = x_train_rgb[:10000]\n",
    "y_train_sub = y_train[:10000]\n",
    "\n",
    "# Regularization values\n",
    "c_values = [0.01, 0.1, 1, 10, 100]\n",
    "test_accuracies = []\n",
    "\n",
    "# Run Logistic Regression for each C value\n",
    "for c in c_values:\n",
    "    model = LogisticRegression(C=c, solver='saga', max_iter=300, multi_class='multinomial', n_jobs=-1)\n",
    "    model.fit(x_train_sub, y_train_sub)\n",
    "    y_pred = model.predict(x_test_rgb)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    test_accuracies.append(acc)\n",
    "    print(f\"C={c}: Test Accuracy={acc:.4f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(c_values, test_accuracies, marker='o', linestyle='--', color='blue')\n",
    "plt.xscale('log')\n",
    "plt.title(\"Phase 4: Accuracy vs. Regularization Strength (C)\")\n",
    "plt.xlabel(\"C (Inverse of Regularization Strength)\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0510dc87-88e1-48ad-a888-1bf0092efc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
